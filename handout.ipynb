{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TME8YpA65K6z"
   },
   "source": [
    "# Inhalt\n",
    "1. [Einführung](#problem)\n",
    "2. [Dataset](#dataset)\n",
    "3. [Code](#code)\n",
    "4. [Fazit](#fazit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3kDLPzBZABn"
   },
   "source": [
    "## Einführung <a name=\"problem\"></a>\n",
    "\n",
    "Der Kartoffelanbau ist ein zentraler Pfeiler der Landwirtschaft, der jedoch kontinuierlich durch Pflanzenkrankheiten bedroht wird. Eine der größten Gefahren stellt die Kraut- und Knollenfäule (Late Blight) dar. Diese Krankheit ist hochinfektiös und kann sich unter günstigen Witterungsbedingungen extrem schnell ausbreiten, was oft zum Totalverlust ganzer Felder führt. Auch die Alternaria-Dürrfleckenkrankheit (Early Blight) beeinträchtigt die Pflanzengesundheit und reduziert den Ertrag erheblich.\n",
    "\n",
    "Die traditionelle Feldüberwachung erfolgt manuell durch Landwirte oder Agronomen. Dieser Prozess ist zeitaufwendig, teuer und oft nicht schnell genug, um auf einen aggressiven Ausbruch wie Late Blight rechtzeitig zu reagieren.\n",
    "\n",
    "Hier setzt unser Projekt an: Das Ziel ist die Entwicklung eines automatisierten Monitoring-Systems auf Basis von Computer Vision. Durch die Analyse von Bilddaten der Kartoffelblätter soll das System in der Lage sein, einen Befall durch Early Blight oder Late Blight frühzeitig und zuverlässig zu erkennen.\n",
    "\n",
    "Der Mehrwert dieser Lösung liegt in der direkten Unterstützung des landwirtschaftlichen Managements. Wir definieren den Erfolg dieses Projekts anhand der folgenden drei Kriterien:\n",
    "\n",
    "  1. Zuverlässige Erkennung zur Ertragssicherung: Das System muss eine hohe Genauigkeit bei der Identifizierung der Krankheiten aufweisen. Eine frühzeitige Warnung ermöglicht es dem Landwirt, sofortige und gezielte Gegenmaßnahmen einzuleiten und so den Ertrag zu sichern.\n",
    "\n",
    "  2. Minimierung unnötiger Kosten: Durch die präzise Lokalisierung von Krankheitsherden kann der Einsatz von Pflanzenschutzmitteln (Fungiziden) optimiert werden. Anstatt ganze Felder präventiv zu behandeln, erlaubt das System eine bedarfsgerechte Anwendung. Dies senkt die Betriebskosten und schont die Umwelt.\n",
    "\n",
    "  3. Nachweis der Wirksamkeit der Maßnahme: Im finalen Schritt muss messbar nachgewiesen werden, dass der Einsatz des automatisierten Systems zu einer effektiveren Krankheitskontrolle und damit zu einer messbaren Reduzierung von Ernteausfällen im Vergleich zu traditionellen Methoden führt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCxWbieb51wS"
   },
   "source": [
    "## Dataset <a name=\"dataset\"></a>\n",
    "\n",
    "### 1. Quelle und Übersicht\n",
    "\n",
    "Der für dieses Projekt verwendete Datensatz ist eine Sammlung von Bildern, die Blätter von Kartoffelpflanzen zeigen. Er wurde von der Online-Plattform Kaggle bezogen und ist öffentlich für Forschungs- und Entwicklungszwecke im Bereich Computer Vision verfügbar.\n",
    "\n",
    "    Quelle: https://www.kaggle.com/datasets/faysalmiah1721758/potato-dataset\n",
    "\n",
    "### 2. Inhalt und Klassen\n",
    "\n",
    "Der Datensatz dient der Klassifizierung von drei verschiedenen Zuständen eines Kartoffelblattes. Jedes Bild ist einer der folgenden drei Kategorien zugeordnet:\n",
    "\n",
    "  - Potato Early blight: Bilder von Blättern, die Symptome der Dürrfleckenkrankheit aufweisen.\n",
    "\n",
    "  - Potato Late blight: Bilder von Blättern, die von der Kraut- und Knollenfäule befallen sind.\n",
    "\n",
    "   - Potato healthy: Bilder von gesunden Blättern ohne sichtbare Krankheitsanzeichen.\n",
    "\n",
    "### 3. Datenverteilung\n",
    "\n",
    "Der Datensatz besteht aus insgesamt 2152 Bildern. Die Aufteilung auf die einzelnen Klassen ist wie folgt:\n",
    "\n",
    "| Klasse | Anzahl |\n",
    "|:---|---:|\n",
    "| Potato Early blight (Alternaria-Dürrfleckenkrankheit) | 1000 |\n",
    "| Potato Late blight (Kraut- und Knollenfäule) | 1000 |\n",
    "| Potato healthy (gesunde Blätter) | 152 |\n",
    "| **Gesamt** | **2152** |\n",
    "\n",
    "### 4. Beispielbilder\n",
    "\n",
    "<table style=\"width:100%; border:0;\">\n",
    "  <tr style=\"text-align: center;\">\n",
    "    <td><img src=\"https://github.com/Mupx/Kartoffel_CNN/blob/main/Beispielbilder/healthy.JPG?raw=true\" width=\"200\"></td>\n",
    "    <td><img src=\"https://github.com/Mupx/Kartoffel_CNN/blob/main/Beispielbilder/early_blight.jpg?raw=true\" width=\"200\"></td>\n",
    "    <td><img src=\"https://github.com/Mupx/Kartoffel_CNN/blob/main/Beispielbilder/late_blight.JPG?raw=true\" width=\"200\"></td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr style=\"text-align: center;\">\n",
    "    <td>Healthy</td>\n",
    "    <td>Early Blight</td>\n",
    "    <td>Late Blight</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "### 5. Anmerkung zum Klassenungleichgewicht\n",
    "\n",
    "Wie aus der Tabelle ersichtlich ist, liegt ein signifikantes Klassenungleichgewicht (Class Imbalance) vor. Die beiden Krankheitsklassen sind mit jeweils 1000 Bildern stark vertreten, während die Klasse der gesunden Blätter mit 152 Bildern deutlich unterrepräsentiert ist.\n",
    "\n",
    "Dieses Ungleichgewicht muss beim Training von Machine-Learning-Modellen berücksichtigt werden, um eine Verzerrung (Bias) des Modells zugunsten der Mehrheitsklassen zu vermeiden. Mögliche Gegenmaßnahmen sind beispielsweise:\n",
    "\n",
    "  - Datenerweiterung (Data Augmentation) speziell für die unterrepräsentierte Klasse.\n",
    "\n",
    "  - Oversampling der \"healthy\"-Klasse (z. B. mittels SMOTE).\n",
    "\n",
    "  - Undersampling der \"blight\"-Klassen.\n",
    "\n",
    "  - Verwendung einer gewichteten Verlustfunktion (Weighted Loss Function) während des Trainings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EPc6Y8CxI9l"
   },
   "source": [
    "## Code <a name=\"code\"></a>\n",
    "\n",
    "Die Code Zellen können nacheinander einzeln ausgeführt werden.\n",
    "Die Zellen für die visualisierung der Feature Maps sind für das Training nicht notwendig und können übersprungen werden.\n",
    "\n",
    " Es werden alle notwendigen Bibliotheken imiportiert:\n",
    " - kagglehub: Zum Herunterladen des Datensatzes von Kaggle.\n",
    " - tensorflow & keras: Das Haupt-Framework für den Aufbau und das Training des Neuronalen Netzes.\n",
    " - ImageDataGenerator: Ein Keras-Werkzeug, um Bilder von der Festplatte zu laden,\n",
    "   sie \"on-the-fly\" zu augmentieren (z.B. drehen, zoomen) und in Batches an das Modell zu übergeben.\n",
    " - regularizers: Wird benötigt, um Regularisierungstechniken (wie L2) auf die Schichten\n",
    "   des Modells anzuwenden, was Overfitting reduziert.\n",
    " - compute_class_weight: Eine Scikit-learn-Funktion, die hilft, das Modell-Training\n",
    "   bei unausgewogenen Datensätzen (ungleiche Anzahl von Bildern pro Klasse) zu balancieren.\n",
    " - numpy: Standardbibliothek für numerische Operationen.\n",
    " - matplotlib.pyplot: Wird verwendet, um die Trainingsergebnisse zu visualisieren.\n",
    " - pathlib.Path: Bietet eine moderne, objektorientierte Schnittstelle zur Handhabung von Dateipfaden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pBpIZcuF3KM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK02UlBHx5SO"
   },
   "source": [
    " Diese Zelle lädt den \"Potato Dataset\" mithilfe der `kagglehub`-Bibliothek herunter.\n",
    " Der zurückgegebene Pfad (`path`) zeigt auf den lokalen Speicherort des Datensatzes.\n",
    "  Anschließend wird der Datensatz mit `pathlib` durchsucht. Die Schleife dient als\n",
    " \"Sanity Check\": Sie iteriert durch alle Unterordner, gibt deren Namen aus\n",
    " (die typischerweise den Klassennamen entsprechen, z.B. `Potato___Early_blight`)\n",
    " und zählt die Anzahl der Bilddateien in jedem Ordner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIhXCMNd4yCP"
   },
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"faysalmiah1721758/potato-dataset\")\n",
    "print(f\"Dataset Pfad: {path}\")\n",
    "\n",
    "dataset_path = Path(path)\n",
    "for item in dataset_path.rglob(\"*\"):\n",
    "    if item.is_dir():\n",
    "        print(f\"Ordner Name: {item.name}\")\n",
    "        image_count = len(list(item.glob(\"*.png\"))) + len(list(item.glob(\"*.jpg\"))) + len(list(item.glob(\"*.jpeg\")))\n",
    "        if image_count > 0:\n",
    "            print(f\"{image_count} Bilder gefunden\")\n",
    "        else:\n",
    "            print(\"Keine Bilder gefunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZiaAGIVyjuX"
   },
   "source": [
    " Hier werden die grundlegenden Hyperparameter für das Training festgelegt.\n",
    "\n",
    " - IMG_SIZE = 224: Definiert die Zielgröße (224x224 Pixel), auf die alle Bilder\n",
    "   skaliert werden. CNNs benötigen eine einheitliche Eingabegröße. 224x224 ist\n",
    "   ein gängiger Standard, der von vielen bekannten Architekturen (wie VGG) verwendet wird.\n",
    "\n",
    " - BATCH_SIZE = 32: Legt fest, wie viele Bilder das Modell auf einmal verarbeitet,\n",
    "   bevor es seine Gewichte aktualisiert. 32 ist ein üblicher Kompromiss zwischen\n",
    "   Recheneffizienz, Speicherbedarf und Stabilität des Trainings.\n",
    "\n",
    " - train_dir: Speichert den Pfad zum Hauptverzeichnis des Datensatzes für späteren Zugriff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUOeBhRo45_U"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = dataset_path #Trainingsordner\n",
    "\n",
    "print(f\"Trainingsorder ist {train_dir}\")\n",
    "print(f\"Bildgroesse ist {IMG_SIZE} X {IMG_SIZE}\")\n",
    "print(f\"Es werden {BATCH_SIZE} Bilder pro Batch (auf einmal) betrachtet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwmzG5u4y3vJ"
   },
   "source": [
    " Diese Zelle bereitet die Bilddaten für das Training vor.\n",
    " Der `ImageDataGenerator` wird mit drei Hauptaufgaben konfiguriert:\n",
    "\n",
    " 1. Normierung (`rescale=1/255`):\n",
    "    Dies ist ein essenzieller Schritt. Alle Pixelwerte (ursprünglich [0, 255]) werden\n",
    "    auf den Bereich [0, 1] skaliert. Neuronale Netze lernen mit diesen kleineren Werten\n",
    "    wesentlich effizienter und stabiler.\n",
    "\n",
    " 2. Data Augmentation (z.B. `rotation_range`, `zoom_range`...):\n",
    "    Das Modell wird mit künstlich veränderten Versionen der Trainingsbilder trainiert\n",
    "    (zufällig gedreht, gezoomt, gespiegelt etc.). Dies vergrößert den Datensatz virtuell\n",
    "    und ist eine sehr effektive Methode, um Overfitting zu reduzieren, da das Modell\n",
    "    lernt, robust gegenüber leichten Variationen zu sein.\n",
    "\n",
    " 3. Validation Split (`validation_split=0.2`):\n",
    "    20% der Daten werden automatisch für die Validierung reserviert.\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFSg-RXgy1Jt"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255, #RGB Werte werden normiert\n",
    "    rotation_range=20, #Max 20° rotation\n",
    "    width_shift_range=0.2, #Verschiebung links-recht (Relativ zur Breite)\n",
    "    height_shift_range=0.2, #Verschiebung unten-oben (Relativ zur Höhe)\n",
    "    shear_range=0.2, #Verzerrung\n",
    "    zoom_range=0.2,#Zufälliger Zoom 0,8 bis 1,2\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2, #20% werden zur Validierung verwendet\n",
    ")\n",
    "\n",
    "# Generator für die Trainingsdaten.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Generator für die Validierungsdaten.\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "print(f\"Gefundene Klassen: {train_generator.class_indices}\")\n",
    "num_classes = len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13bnxb1o0UCe"
   },
   "source": [
    " Diese Zelle definiert die Architektur des Convolutional Neural Network (CNN)\n",
    " als Funktion. Das Modell ist ein `Sequential`-Stack von Schichten.\n",
    "\n",
    " Faltungs-Blöcke (Merkmalsextraktion):\n",
    " Das Modell besteht aus drei Faltungs-Blöcken. Jeder Block folgt einem gängigen Muster:\n",
    " 1. `Conv2D`: Wendet Filter (z.B. 32, dann 64, dann 128) an, um Muster zu erkennen\n",
    "    (Kanten, Texturen). `padding='same'` sorgt dafür, dass die Bildgröße durch\n",
    "    die Faltung nicht schrumpft.\n",
    " 2. `BatchNormalization`: Stabilisiert und beschleunigt das Training durch\n",
    "    Normalisierung der Aktivierungen zwischen den Schichten.\n",
    " 3. `Activation('relu')`: Führt Nichtlinearität ein (`f(x) = max(0, x)`), damit\n",
    "    das Netz komplexe Zusammenhänge lernen kann.\n",
    " 4. `MaxPooling2D`: Reduziert die räumliche Auflösung (Downsampling). Dies spart\n",
    "    Rechenleistung und macht das Modell robuster gegenüber kleinen Verschiebungen im Bild.\n",
    "\n",
    " Klassifikations-Blöcke (Entscheidungsfindung):\n",
    " 1. `Flatten`: Wandelt die 3D-Feature-Maps (Höhe x Breite x Kanäle) aus dem\n",
    "    letzten Faltungsblock in einen langen 1D-Vektor um.\n",
    " 2. `Dense(256)`: Eine voll verbundene Schicht, die die gelernten Merkmale kombiniert.\n",
    " 3. `kernel_regularizer=regularizers.l2(0.001)`: Wendet L2-Regularisierung an\n",
    "    (eine \"Strafe\" für große Gewichte), um Overfitting zu reduzieren.\n",
    " 4. `Dropout(0.4)`: Deaktiviert während des Trainings zufällig 40% der Neuronen\n",
    "    in dieser Schicht. Dies zwingt das Netz, redundante Informationen zu lernen\n",
    "    und ist eine sehr effektive Methode gegen Overfitting.\n",
    " 5. `Dense(num_classes, activation='softmax')`: Die finale Output-Schicht. Sie hat\n",
    "    so viele Neuronen, wie es Klassen gibt (`num_classes`). Die `softmax`-Aktivierung\n",
    "    wandelt die Ausgabe in eine Wahrscheinlichkeitsverteilung um (alle Ausgaben\n",
    "    summieren sich zu 1), die angibt, wie sicher sich das Modell bei jeder Klasse ist.\n",
    "\n",
    " `summary()` gibt eine textuelle Zusammenfassung der Modellarchitektur aus,\n",
    " die die Schichten, ihre Ausgabe-Formen und die Anzahl der Parameter zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJwsWVi90Fqv"
   },
   "outputs": [],
   "source": [
    "def create_small_cnn(num_classes):\n",
    "    model = keras.Sequential([\n",
    "\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3, 3), padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3, 3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # Klassifikations-Teil\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Erstellen des Modells\n",
    "model = create_small_cnn(num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UEaLndJ05lG"
   },
   "source": [
    " Diese Zelle definiert eine komplexe Hilfsfunktion, `save_feature_maps_comparison`,\n",
    " um die internen Vorgänge des CNNs zu visualisieren.\n",
    "\n",
    " Was sind Feature Maps?\n",
    " Eine Feature Map ist die Ausgabe eines Filters in einer `Conv2D`-Schicht.\n",
    " Sie zeigt, welche Bereiche des Bildes diesen spezifischen Filter \"aktiviert\" haben.\n",
    " Die Visualisierung hilft zu verstehen, worauf das Netz \"achtet\" (z.B. Kanten, Texturen).\n",
    "\n",
    " Was macht die Funktion?\n",
    " 1. Sie identifiziert alle `Conv2D`-Schichten im Modell.\n",
    " 2. Sie erstellt ein neues \"Sub-Modell\" (`feature_map_model`), das denselben\n",
    "    Input wie das Originalmodell nimmt, aber als Output die Aktivierungen\n",
    "    (die Feature Maps) *jeder* `Conv2D`-Schicht zurückgibt.\n",
    " 3. Sie führt ein Testbild (`img_array`) durch dieses Sub-Modell, um die\n",
    "    Feature Maps zu berechnen.\n",
    " 4. Sie iteriert durch die Feature Maps jeder Schicht und speichert für jede\n",
    "    Schicht ein Bild. Dieses Bild zeigt das Originalbild links und rechts\n",
    "    daneben drei Beispiel-Feature-Maps (die erste, die mittlere und die letzte)\n",
    "    aus dieser Schicht.\n",
    " 5. Die Bilder werden im Ordner `feature_maps` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8OK1Q1G0xWd"
   },
   "outputs": [],
   "source": [
    "def save_feature_maps_comparison(model, img_array, save_dir='feature_maps'):\n",
    "    \"\"\"\n",
    "    Speichert Original-Bild und jeweils 3 Feature Maps pro Conv-Block\n",
    "    \"\"\"\n",
    "\n",
    "    Path(save_dir).mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "    conv_layer_names = [layer.name for layer in model.layers\n",
    "                        if 'conv' in layer.name.lower()]\n",
    "\n",
    "    # Feature Map Modell erstellen\n",
    "    layer_outputs = [model.get_layer(name).output for name in conv_layer_names]\n",
    "    feature_map_model = keras.Model(\n",
    "        inputs=model.layers[0].input,\n",
    "        outputs=layer_outputs\n",
    "    )\n",
    "\n",
    "    # Feature Maps berechnen\n",
    "    feature_maps = feature_map_model.predict(img_array, verbose=0)\n",
    "\n",
    "    print(f\"\\nSpeichere Feature Maps in Ordner: {save_dir}/\\n\")\n",
    "\n",
    "    # Für jeden Conv-Block: Original + 3 Feature Maps speichern\n",
    "    for block_idx, (layer_name, feature_map) in enumerate(zip(conv_layer_names, feature_maps), 1):\n",
    "        num_features = feature_map.shape[-1]\n",
    "\n",
    "        # Figure mit 4 Subplots erstellen\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        fig.suptitle(f'Block {block_idx}: {layer_name} ({num_features} Feature Maps gesamt)',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Original-Bild\n",
    "        axes[0].imshow(img_array[0])\n",
    "        axes[0].set_title('Original-Bild', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # 3 Feature Maps zeigen\n",
    "        feature_indices = [0, num_features//2, num_features-1] # Erste, mittlere, letzte\n",
    "\n",
    "        for i, feat_idx in enumerate(feature_indices, 1):\n",
    "            if feat_idx < num_features:\n",
    "                channel_image = feature_map[0, :, :, feat_idx]\n",
    "\n",
    "                # Werte für Visualisierung\n",
    "                vmin, vmax = channel_image.min(), channel_image.max()\n",
    "\n",
    "                im = axes[i].imshow(channel_image, cmap='viridis')\n",
    "                axes[i].set_title(f'Feature Map {feat_idx}\\n'\n",
    "                                  f'Range: [{vmin:.2f}, {vmax:.2f}]',\n",
    "                                  fontsize=10)\n",
    "                axes[i].axis('off')\n",
    "\n",
    "                # Colorbar hinzufügen\n",
    "                plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Speichern\n",
    "        filename = f'{save_dir}/block_{block_idx}_{layer_name}.png'\n",
    "        plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "        plt.close() # Figure schließen um Speicher zu sparen\n",
    "\n",
    "        print(f\"[OK] Gespeichert: {filename}\")\n",
    "\n",
    "        # Info ausgeben\n",
    "        print(f\"  Output Shape: {feature_map.shape}\")\n",
    "        print(f\"  Anzahl Feature Maps: {num_features}\")\n",
    "        print(f\"  Spatial Groesse: {feature_map.shape[1]} x {feature_map.shape[2]}\")\n",
    "        print(f\"  Wertebereich: [{feature_map.min():.3f}, {feature_map.max():.3f}]\\n\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Alle Feature Maps wurden erfolgreich gespeichert!\")\n",
    "    print(f\"Ordner: {save_dir}/\")\n",
    "    print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7XZ7HCD1SeN"
   },
   "source": [
    " In dieser Zelle wird die in der vorherigen Zelle definierte Visualisierungsfunktion aufgerufen.\n",
    "\n",
    " 1. `next(train_generator)`: Holt einen einzelnen Batch (32 Bilder) aus dem Trainingsdatensatz.\n",
    " 2. `test_img = test_images[0:1]`: Wählt das erste Bild aus diesem Batch aus.\n",
    "    (Der Slice `[0:1]` statt nur `[0]` wird verwendet, um die Batch-Dimension\n",
    "    `(1, 224, 224, 3)` zu erhalten, die das Modell erwartet.)\n",
    " 3. `save_feature_maps_comparison(...)`: Ruft die Funktion auf, um die Aktivierungen\n",
    "    dieses Testbildes zu berechnen und die Diagramme im Ordner `feature_maps` zu speichern.\n",
    "\n",
    " Wichtiger Hinweis: Das Modell ist zu diesem Zeitpunkt noch **untrainiert**.\n",
    " Die Gewichte sind zufällig, und die Feature Maps werden daher noch keine sinnvollen\n",
    " Muster zeigen. Diese Zelle ist am nützlichsten, wenn man sie *nach* dem\n",
    " erfolgreichen Training des Modells erneut ausführt.\n",
    "\n",
    " Der `print`-Block am Ende gibt eine Interpretation, was man typischerweise\n",
    " in den Feature Maps *nach* dem Training sieht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MPh5vFj1OGw"
   },
   "outputs": [],
   "source": [
    "#Ein Testbild holen\n",
    "test_images, test_labels = next(train_generator)\n",
    "test_img = test_images[0:1] # Erstes Bild nehmen\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE MAPS VISUALISIERUNG - Speichere Bilder...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Feature Maps speichern\n",
    "save_feature_maps_comparison(model, test_img, save_dir='feature_maps')\n",
    "\n",
    "print(\"\"\"\n",
    "ERKLAERUNG DER GESPEICHERTEN BILDER:\n",
    "\n",
    "Block 1 (32 Maps):\n",
    "  - Einfache Muster wie Kanten, Farbverlaeufe\n",
    "  - Hellere Bereiche = staerkere Aktivierung\n",
    "  - Jede Map reagiert auf unterschiedliche Muster\n",
    "\n",
    "Block 2 (64 Maps):\n",
    "  - Kombiniert die 32 Maps von Block 1\n",
    "  - Erkennt komplexere Formen (z.B. Flecken-Raender)\n",
    "  - Kleinere Aufloesung durch MaxPooling\n",
    "\n",
    "Block 3 & 4:\n",
    "  - Noch abstraktere Muster\n",
    "  - Erkennen Kombinationen von Block 2\n",
    "  - Sehr kleine Aufloesung, aber semantisch reich\n",
    "\n",
    "Die Grauwerte sind KONTINUIERLICH, nicht binaer!\n",
    "Das ermoeglicht nuancierte Informationen fuer spaetere Blocks.\n",
    "\n",
    "Schau dir die Bilder im Ordner 'feature_maps' an!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B0JYPDS1feS"
   },
   "source": [
    " Der `model.compile()`-Schritt konfiguriert das Modell für den Trainingsprozess.\n",
    " Hier wird festgelegt, *wie* das Modell lernen soll:\n",
    "\n",
    " 1. `optimizer=keras.optimizers.Adam(learning_rate=initial_lr)`:\n",
    "    Wählt den Optimierungsalgorithmus. `Adam` ist ein sehr beliebter und effektiver\n",
    "    Optimizer, der die Lernrate (`initial_lr = 0.0005`) während des Trainings\n",
    "    intelligent anpasst, um schnell einen guten \"Loss\" (Fehlerwert) zu erreichen.\n",
    "\n",
    " 2. `loss=\"categorical_crossentropy\"`:\n",
    "    Definiert die Verlustfunktion. Diese Funktion misst, wie \"falsch\" die Vorhersagen\n",
    "    des Modells sind. Da wir ein Mehrklassen-Klassifikationsproblem haben (mehr als 2 Klassen)\n",
    "    und unsere Labels im One-Hot-Format vorliegen (`class_mode='categorical'`),\n",
    "    ist dies die Standard-Loss-Funktion. Das Ziel des Trainings ist es, diesen Wert zu minimieren.\n",
    "\n",
    " 3. `metrics=[\"accuracy\"]`:\n",
    "    Gibt an, welche Metriken wir während des Trainings überwachen möchten.\n",
    "    `accuracy` (Genauigkeit) ist der Prozentsatz der korrekt klassifizierten Bilder\n",
    "    und für uns Menschen leichter zu interpretieren als der abstrakte Loss-Wert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hASxMnV_1cr1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Optimizer & Compile\n",
    "initial_lr = 0.0005\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyfeqrbm1qse"
   },
   "source": [
    " Diese Zelle adressiert das Problem der **Klassen-Imbalance**.\n",
    " Wenn der Datensatz unausgewogen ist (z.B. 1000 Bilder von \"gesunden\" Kartoffeln,\n",
    " aber nur 100 von \"kranken\"), könnte das Modell lernen, einfach immer \"gesund\" zu\n",
    " raten, um eine hohe Genauigkeit zu erzielen.\n",
    "\n",
    " `compute_class_weight` von Scikit-learn analysiert die Verteilung der Labels\n",
    " (`train_generator.classes`).\n",
    "\n",
    " - `class_weight='balanced'`: Weist Klassen mit *weniger* Beispielen automatisch\n",
    "   ein *höheres* Gewicht zu.\n",
    " - Das Ergebnis wird in ein Dictionary `class_weights` umgewandelt\n",
    "   (z.B. `{0: 0.8 (häufig), 1: 2.5 (selten)}`).\n",
    "\n",
    " Wenn dieses Dictionary später an `model.fit()` übergeben wird, wird der Loss (Fehler)\n",
    " bei einer falschen Vorhersage für eine seltene Klasse (Klasse 1) mit einem höheren\n",
    " Faktor (2.5) multipliziert. Das Modell wird also stärker \"bestraft\" und gezwungen,\n",
    " diese selteneren Klassen ernster zu nehmen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKax4F7j1oe0"
   },
   "outputs": [],
   "source": [
    "# Class Weights berechnen\n",
    "labels = train_generator.classes\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZXfJXN9182c"
   },
   "source": [
    " Callbacks sind Funktionen, die Keras an bestimmten Punkten im Training\n",
    " aufruft (z.B. am Ende jeder Epoche).\n",
    "\n",
    " Hier wird `EarlyStopping` konfiguriert, eine extrem wichtige Technik,\n",
    " um Overfitting zu bekämpfen und Zeit zu sparen:\n",
    "\n",
    " - `monitor=\"val_loss\"`: Der Callback überwacht den Fehler (Loss) auf dem\n",
    "   **Validierungsdatensatz** (den ungesehenen Daten).\n",
    " - `patience=3`: Das Training wird abgebrochen, wenn sich der `val_loss` für\n",
    "   3 aufeinanderfolgende Epochen nicht signifikant (`min_delta=0.001`) verbessert hat.\n",
    " - `restore_best_weights=True`: Dies ist der wichtigste Parameter. Wenn das Training\n",
    "   z.B. in Epoche 15 abbricht, weil Overfitting begann, stellt dieser Befehl sicher,\n",
    "   dass das Modell automatisch auf den Zustand von Epoche 12 (dem Punkt mit dem\n",
    "   niedrigsten `val_loss`) zurückgesetzt wird. Man erhält somit das Modell mit\n",
    "   der besten Generalisierungsfähigkeit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jD25LJt16eS"
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=3,\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JNj_2hg2OlY"
   },
   "source": [
    " Dies ist der Befehl, der das eigentliche Training startet.\n",
    "\n",
    " - `EPOCHS = 30`: Definiert die *maximale* Anzahl an Durchläufen durch den\n",
    "   gesamten Trainingsdatensatz. Dank `EarlyStopping` (aus den `callbacks`)\n",
    "   wird das Training wahrscheinlich schon früher abbrechen.\n",
    " - `model.fit(...)`: Startet den Trainingsprozess.\n",
    " - `train_generator`: Liefert die Trainingsdaten (Bilder und Labels) in Batches.\n",
    " - `validation_data=val_generator`: Gibt den Generator an, der die Validierungsdaten\n",
    "   liefert. Nach jeder Epoche wird das Modell auf diesen Daten getestet.\n",
    " - `callbacks=callbacks`: Übergibt die zuvor definierte `EarlyStopping`-Funktion.\n",
    " - `class_weight=class_weights`: Übergibt die berechneten Klassengewichte,\n",
    "   um die Klassen-Imbalance auszugleichen.\n",
    "\n",
    " Der Rückgabewert `history` ist ein Objekt, das alle Metriken\n",
    " (loss, accuracy, val_loss, val_accuracy) für jede abgeschlossene Epoche speichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3S26aYP2DT6"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1IojZ2i2X9n"
   },
   "source": [
    " Diese Zelle definiert und ruft eine Funktion (`plot_training_history`) auf,\n",
    " um die Ergebnisse des Trainingsprozesses zu visualisieren. Sie verwendet\n",
    " das `history`-Objekt, das von `model.fit()` zurückgegeben wurde.\n",
    "\n",
    " Es werden zwei Diagramme erstellt:\n",
    " 1. Model Accuracy: Zeigt die Genauigkeit auf den Trainingsdaten (`accuracy`)\n",
    "    und den Validierungsdaten (`val_accuracy`) über die Epochen hinweg.\n",
    " 2. Model Loss: Zeigt den Fehler auf den Trainingsdaten (`loss`) und den\n",
    "    Validierungsdaten (`val_loss`) über die Epochen hinweg.\n",
    "\n",
    " Interpretation der Graphen:\n",
    " - Idealfall: Trainings- und Validierungskurven verlaufen nah beieinander\n",
    "   und verbessern sich (Loss sinkt, Accuracy steigt).\n",
    " - Overfitting: Die Trainingskurve verbessert sich weiter (z.B. `accuracy`\n",
    "   steigt auf 100%), während die Validierungskurve stagniert oder sich\n",
    "   verschlechtert (z.B. `val_loss` steigt an).\n",
    "\n",
    " Das Diagramm wird auch als `training_history.png` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epbR6bY32URE"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Accuracy Graph\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Loss Graph\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_C2bY3Z2qME"
   },
   "source": [
    "In der letzten Zelle werden die Ergebnisse des Trainings für die spätere\n",
    "Verwendung gespeichert.\n",
    "\n",
    " 1. `model.save('potato_disease_model.keras')`:\n",
    "    Speichert das gesamte trainierte Modell (Architektur, die gelernten Gewichte\n",
    "    und die Optimizer-Konfiguration) in einer einzigen Datei im modernen\n",
    "    `.keras`-Format. Diese Datei kann später geladen werden, um Vorhersagen\n",
    "    auf neuen, ungesehenen Bildern zu machen (Inferenz).\n",
    "\n",
    " 2. Klassennamen speichern:\n",
    "    Das Modell selbst gibt nur Zahlen (Indizes) als Vorhersage aus (z.B. `0`, `1`, `2`).\n",
    "    Um diese Zahlen in für Menschen lesbare Namen (z.B. `Potato___healthy`)\n",
    "    zu übersetzen, müssen wir die Zuordnung speichern, die der `ImageDataGenerator`\n",
    "    erstellt hat.\n",
    "    - `train_generator.class_indices` ist ein Dictionary wie `{'Healthy': 0, 'Sick': 1}`.\n",
    "    - Wir drehen dieses Dictionary um (`{0: 'Healthy', 1: 'Sick'}`) und speichern\n",
    "      es als `class_names.json`-Datei.\n",
    "    - Bei der späteren Inferenz laden wir das Modell *und* diese JSON-Datei,\n",
    "      um die numerischen Vorhersagen zu \"übersetzen\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsYjaJDD2nf3"
   },
   "outputs": [],
   "source": [
    "model.save('potato_disease_model.keras')\n",
    "\n",
    "# Klassennamen speichern\n",
    "import json\n",
    "class_names = {v: k for k, v in train_generator.class_indices.items()}\n",
    "with open(\"class_names.json\", \"w\") as f:\n",
    "    json.dump(class_names, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ol9yRAI0QwhB"
   },
   "source": [
    " ## Fazit <a name=\"fazit\"></a>\n",
    "\n",
    "### Analyse der Trainingsergebnisse\n",
    "\n",
    "Die Trainings- und Validierungsgrafiken (siehe Abb. 1) zeigen ein sehr positives Ergebnis.\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://github.com/Mupx/Kartoffel_CNN/blob/main/Bilder/training_history_normal.png?raw=true\" alt=\"Training Historie\">\n",
    "  <figcaption>Abb. 1: Training Historie.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Nach einer initialen Phase (ca. bis Epoche 8), in der das Modell noch Schwierigkeiten hatte, die Muster der unterrepräsentierten \"healthy\"-Klasse zu generalisieren (erkennbar an der stagnierenden/fluktuierenden Validierungskurve), stabilisierte sich der Lernprozess deutlich.\n",
    "\n",
    "Ab Epoche 10 konvergieren die Kurven für Training und Validierung eindrucksvoll:\n",
    "\n",
    "  - Hohe Genauigkeit (Accuracy): Sowohl die Trainings- als auch die Validierungsgenauigkeit erreichen am Ende der 25 Epochen einen Wert von ca. 98 %.\n",
    "\n",
    "  - Keine Überanpassung (Overfitting): Die Genauigkeitskurven (links) bleiben eng beieinander, und die Verlustkurven (Loss, rechts) konvergieren ebenfalls auf einen gemeinsamen, niedrigen Wert. Dies ist ein starkes Indiz dafür, dass das Modell die gelernten Muster gut auf ungesehene Daten übertragen kann und nicht nur den Trainingsdatensatz auswendig gelernt hat.\n",
    "\n",
    "Die erfolgreiche Konvergenz ist ein direkter Beleg dafür, dass die Anwendung der Klassengewichtung (Class Weighting) zur Kompensation des Datenungleichgewichts erfolgreich war. Ohne diese Maßnahme wäre die Validierungsgenauigkeit (insbesondere für die \"healthy\"-Klasse) voraussichtlich deutlich schlechter ausgefallen.\n",
    "\n",
    "### Bezug zu den Erfolgskriterien\n",
    "\n",
    "Die hohe Validierungsgenauigkeit von ~98 % ist ein entscheidender Schritt zur Erfüllung unseres primären Erfolgskriteriums: \"Zuverlässige Erkennung zur Ertragssicherung\".\n",
    "\n",
    "Ein Modell, das mit dieser Präzision zwischen gesunden und kranken Blättern unterscheiden kann, legt den Grundstein für die weiteren Ziele:\n",
    "\n",
    "  - Es ermöglicht eine präzise Alarmierung und damit eine gezielte Behandlung, was die unnötigen Kosten (Erfolgskriterium 2) durch pauschales Spritzen minimiert.\n",
    "\n",
    "  - Es liefert die notwendige Datengrundlage, um die Wirksamkeit der Maßnahme (Erfolgskriterium 3) im Feldeinsatz zu messen."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmTzF87Edjd3A9z5kb8kwB",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
